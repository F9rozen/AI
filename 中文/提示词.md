提示词工程
利用及时的工程策略来提高成果。
本指南分享了从 GPT-4o 等大型语言模型（有时称为 GPT 模型）中获得更好结果的策略和技巧。此处描述的方法有时可以组合使用以获得更好的效果。我们鼓励您进行实验以找到最适合您的方法。

您还可以探索展示我们的模型功能的示例提示：

提示示例
探索提示示例以了解 GPT 模型可以做什么

取得更好结果的六大策略
写下清晰的说明
这些模型无法读懂你的想法。如果输出太长，请要求简短回复。如果输出太简单，请要求专家级写作。如果你不喜欢这种格式，请演示你想要看到的格式。模型猜测你想要什么的次数越少，你得到它的可能性就越大。

策略：

在您的查询中包含详细信息以获取更相关的答案
要求模特采用角色
使用分隔符清楚地指示输入的不同部分
指定完成任务所需的步骤
提供例子
指定所需的输出长度
提供参考文本
语言模型可以自信地编造虚假答案，尤其是在被问及深奥的话题或引用和 URL 时。就像一张笔记可以帮助学生在考试中取得更好的成绩一样，向这些模型提供参考文本可以帮助他们用更少的编造来回答问题。

策略：

指示模型使用参考文本回答
指示模型使用参考文本的引用来回答
将复杂任务拆分为更简单的子任务
正如在软件工程中将复杂系统分解为一组模块化组件是一种很好的做法一样，提交给语言模型的任务也是如此。复杂任务的错误率往往高于简单任务。此外，复杂任务通常可以重新定义为简单任务的工作流程，其中较早任务的输出用于构建后续任务的输入。

策略：

使用意图分类来识别与用户查询最相关的说明
对于需要长时间对话的对话应用，总结或过滤之前的对话
分段总结长文档并递归构建完整摘要
给模型时间“思考”
如果要求您将 17 乘以 28，您可能无法立即知道答案，但随着时间的推移仍然可以算出答案。同样，模型在尝试立即回答时会犯更多推理错误，而不是花时间找出答案。在回答之前要求“思路”可以帮助模型更可靠地推理出正确答案。

策略：

指导模型在匆忙得出结论之前找到自己的解决方案
使用内心独白或一系列查询来隐藏模型的推理过程
询问模型在之前的传递中是否遗漏了什么
使用外部工具
通过向模型提供其他工具的输出来弥补模型的弱点。例如，文本检索系统（有时称为 RAG 或检索增强生成）可以告知模型相关文档。像 OpenAI 的代码解释器这样的代码执行引擎可以帮助模型进行数学运算和运行代码。如果某项任务可以通过工具而不是语言模型更可靠或更高效地完成，则可以将其卸载以充分利用两者的优势。

策略：

使用基于嵌入的搜索实现高效的知识检索
使用代码执行进行更精确的计算或调用外部 API
授予模型访问特定功能的权限
系统地测试变化
如果可以测量，则提高性能会更容易。在某些情况下，对提示的修改将在几个孤立示例上实现更好的性能，但在更具代表性的示例集上导致整体性能下降。因此，为了确保更改对性能有净积极影响，可能需要定义一个全面的测试套件（也称为“评估”）。

策略：

参考黄金标准答案评估模型输出
策略
上面列出的每一种策略都可以用具体的策略来实例化。这些策略旨在提供一些可以尝试的想法。它们绝不是完全全面的，你应该随意尝试这里没有提到的创造性想法。

策略：写下清晰的说明
策略：在查询中包含详细信息以获得更相关的答案
为了获得高度相关的响应，请确保请求提供所有重要细节或背景信息。否则，您将让模型来猜测您的意思。

更糟的是	更好的
如何在 Excel 中添加数字？	如何在 Excel 中将一行美元金额相加？我想自动对整张表的行执行此操作，所有总计最终显示在右侧名为“总计”的列中。
谁是总统？	2021 年墨西哥总统是谁？选举频率是多少？
编写代码计算斐波那契数列。	编写一个 TypeScript 函数来高效计算斐波那契数列。对代码进行大量注释，解释每个部分的作用以及为什么这样编写。
总结会议记录。	用一段话总结会议记录。然后写下演讲者及其要点的简要列表。最后，列出演讲者建议的后续步骤或行动项目（如果有）。
策略：要求模特采用角色
系统消息可用于在回复中指定模型所使用的角色。

系统
当我请求帮助写一些东西时，你会回复一份文件，其中每一段至少包含一个笑话或俏皮的评论。
用户
写一封感谢信给我的钢螺栓供应商，感谢他们在短时间内准时交货。这让我们能够交付一份重要的订单。
策略：使用分隔符清楚地指示输入的不同部分
三重引号、XML 标签、章节标题等分隔符可以帮助划分需要不同处理的文本部分。

用户
用俳句总结用三重引号分隔的文本。“”“在此处插入文本””
系统
您将获得关于同一主题的两篇文章（以 XML 标签分隔）。首先总结每篇文章的论点。然后指出其中哪篇文章的论点更好并解释原因。
用户
<article> 在此处插入第一篇文章 </article> <article> 在此处插入第二篇文章 </article>
系统
您将收到一份论文摘要和建议的标题。论文标题应该让读者对论文的主题有一个很好的了解，但也应该引人注目。如果标题不符合这些标准，请建议 5 个替代方案。
用户
摘要：在此处插入摘要 标题：在此处插入标题
对于这类简单的任务，使用分隔符可能不会对输出质量产生影响。但是，任务越复杂，消除任务细节的歧义就越重要。不要让模型努力理解你对它们的要求。

策略：指定完成任务所需的步骤
有些任务最好以一系列步骤的形式来描述。明确地写出这些步骤可以让模型更容易遵循它们。

系统
使用以下分步说明来响应用户输入。步骤 1 - 用户将向您提供三引号中的文本。用一个句子总结此文本，前缀为“摘要：”。步骤 2 - 将步骤 1 中的摘要翻译成西班牙语，前缀为“翻译：”。
用户
“”“在此处插入文本””
策略：提供例子
提供适用于所有示例的一般说明通常比通过示例演示任务的所有排列更有效，但在某些情况下，提供示例可能更容易。例如，如果您希望模型复制一种难以明确描述的特定用户查询响应风格。这被称为“少量”提示。

系统
以一致的风格回答。
用户
教我什么是耐心。
助手
冲刷最深山谷的河流，源自一股温和的泉源；最宏大的交响乐，源自一个音符；最精致的挂毯，始于一根孤独的线。
用户
教我有关海洋的知识。
策略：指定所需的输出长度
您可以要求模型生成具有给定目标长度的输出。目标输出长度可以根据单词、句子、段落、要点等的数量来指定。但请注意，指示模型生成特定数量的单词并不能实现高精度。该模型可以更可靠地生成具有特定数量的段落或要点的输出。

用户
用三重引号分隔的文本总结大约 50 个字。“”“在此处插入文本””
用户
用两段文字概括用三重引号分隔的文本。"""在此处插入文本"""
用户
用三引号分隔的文本总结为 3 个要点。“”“在此处插入文本””
策略：提供参考文本
策略：指导模型使用参考文本回答
如果我们可以为模型提供与当前查询相关的可信信息，那么我们就可以指示模型使用提供的信息来组成其答案。

系统
使用提供的以三重引号分隔的文章来回答问题。如果在文章中找不到答案，请写“我找不到答案”。
用户
<插入冠词，每个冠词用三重引号分隔> 问题：<在此处插入问题>
鉴于所有模型的上下文窗口都有限，我们需要某种方式来动态查找与所提问题相关的信息。嵌入可用于实现高效的知识检索。有关如何实现此目的的更多详细信息，请参阅策略“使用基于嵌入的搜索实现高效的知识检索” 。

策略：指示模型用参考文本中的引文来回答
如果输入已补充相关知识，则可以直接要求模型通过引用所提供文档中的段落为其答案添加引文。请注意，然后可以通过所提供文档中的字符串匹配以编程方式验证输出中的引文。

系统
您将获得一份由三重引号分隔的文档和一个问题。您的任务是仅使用所提供的文档回答问题，并引用用于回答问题的文档段落。如果文档不包含回答此问题所需的信息，则只需写：“信息不足”。如果提供了问题的答案，则必须用引文注释。使用以下格式引用相关段落（{“citation”：…}）。
用户
"""<在此处插入文档>""" 问题：<在此处插入问题>
策略：将复杂任务拆分为更简单的子任务
策略：使用意图分类来识别与用户查询最相关的指令
对于需要大量独立指令集来处理不同情况的任务，首先对查询类型进行分类并使用该分类来确定需要哪些指令会很有帮助。这可以通过定义固定类别和硬编码与处理给定类别中的任务相关的指令来实现。此过程还可以递归应用，以将任务分解为一系列阶段。这种方法的优点是每个查询将仅包含执行任务下一阶段所需的指令，与使用单个查询执行整个任务相比，这可以降低错误率。这还可以降低成本，因为更大的提示运行成本更高（请参阅定价信息）。

例如，假设对于客户服务应用程序，查询可以按如下方式进行有用分类：

系统
您将获得客户服务查询。将每个查询分为主要类别和次要类别。以 json 格式提供输出，键为：主要和次要。主要类别：计费、技术支持、帐户管理或一般查询。计费次要类别：- 取消订阅或升级 - 添加付款方式 - 收费说明 - 对收费提出异议技术支持次要类别：- 故障排除 - 设备兼容性 - 软件更新帐户管理次要类别：- 密码重置 - 更新个人信息 - 关闭帐户 - 帐户安全一般查询次要类别：- 产品信息 - 定价 - 反馈 - 与人交谈
用户
我需要让我的互联网重新运行。
根据客户查询的分类，可以向模型提供一组更具体的指令，以便其处理后续步骤。例如，假设客户需要“故障排除”方面的帮助。

系统
您将收到需要在技术支持环境中进行故障排除的客户服务咨询。通过以下方式帮助用户： - 要求他们检查路由器的所有电缆是否已连接。请注意，电缆随着时间的推移松动是很常见的。 - 如果所有电缆都已连接但问题仍然存在，请询问他们正在使用哪种路由器型号 - 现在您将建议他们如何重新启动设备： -- 如果型号是 MTD-327J，建议他们按下红色按钮并按住 5 秒钟，然后等待 5 分钟再测试连接。 -- 如果型号是 MTD-327S，建议他们拔下并重新插入，然后等待 5 分钟再测试连接。 - 如果客户在重新启动设备并等待 5 分钟后问题仍然存在，请通过输出 {“请求 IT 支持”} 将他们连接到 IT 支持。 - 如果用户开始询问与此主题无关​​的问题，请确认他们是否要结束当前有关故障排除的聊天，并根据以下方案对其请求进行分类：<在此处插入上面的主要/次要分类方案>
用户
我需要让我的互联网重新运行。
请注意，模型已被指示发出特殊字符串来指示对话状态何时发生变化。这使我们能够将系统变成状态机，其中状态决定注入哪些指令。通过跟踪状态、该状态下哪些指令相关以及可选地允许从该状态进行哪些状态转换，我们可以为用户体验设置护栏，而这很难通过结构化程度较低的方法实现。

策略：对于需要长时间对话的对话应用程序，总结或过滤之前的对话
由于模型具有固定的上下文长度，因此用户和助手之间的对话（其中整个对话包含在上下文窗口中）不能无限期地继续下去。

这个问题有多种解决方法，其中一种是总结对话中的前几轮。一旦输入的大小达到预定的阈值长度，这可能会触发一个总结部分对话的查询，并且前一次对话的摘要可以作为系统消息的一部分。或者，可以在整个对话过程中在后台异步总结前一次对话。

另一种解决方案是动态选择与当前查询最相关的对话的先前部分。请参阅策略“使用基于嵌入的搜索实现高效的知识检索”。

策略：分段总结长文档并递归构建完整摘要
由于模型具有固定的上下文长度，因此它们不能用于在单个查询中汇总长度超过上下文长度减去生成的摘要的长度的文本。

要总结非常长的文档（例如一本书），我们可以使用一系列查询来总结文档的每个部分。可以将各部分摘要连接起来并进行总结，从而生成摘要的摘要。此过程可以递归进行，直到总结整个文档。如果需要使用有关前面部分的信息来理解后面的部分，那么另一个有用的技巧是在总结该部分内容的同时，在书中任何给定点之前包含文本的连续摘要。OpenAI 在之前的研究中使用 GPT-3 变体研究了此程序对总结书籍的有效性。

策略：给模型时间“思考”
策略：在匆忙得出结论之前，指导模型自己找到解决方案
有时，当我们明确指示模型在得出结论之前从第一原理进行推理时，我们会得到更好的结果。例如，假设我们想要一个模型来评估学生对数学问题的解决方案。最明显的方法是直接询问模型学生的解决方案是否正确。

系统
确定学生的解决方案是否正确。
用户
问题陈述：我正在建造一个太阳能发电装置，我需要帮助计算财务状况。 - 土地成本为每平方英尺 100 美元 - 我可以以每平方英尺 250 美元的价格购买太阳能电池板 - 我协商了一份维护合同，每年将花费我 10 万美元，另外每平方英尺还要花费 10 美元 作为平方英尺数的函数，第一年运营的总成本是多少。 学生的解决方案：让 x 表示装置的面积（以平方英尺为单位）。 1. 土地成本：100x 2. 太阳能电池板成本：250x 3. 维护成本：100,000 + 100x 总成本：100x + 250x + 100,000 + 100x = 450x + 100,000
助手
这位学生的解答是正确的。
但这位学生的解决方案其实并不正确！我们可以通过提示模型先生成自己的解决方案来让模型成功注意到这一点。

系统
首先自己想出解决问题的方案。然后将你的方案与学生的方案进行比较，并评估学生的方案是否正确。在你自己解决完问题之前，不要判断学生的方案是否正确。
用户
问题陈述：我正在建造一个太阳能发电装置，我需要帮助计算财务状况。 - 土地成本为每平方英尺 100 美元 - 我可以以每平方英尺 250 美元的价格购买太阳能电池板 - 我协商了一份维护合同，每年将花费我 10 万美元，另外每平方英尺还要花费 10 美元 作为平方英尺数的函数，第一年运营的总成本是多少。 学生的解决方案：让 x 表示装置的面积（以平方英尺为单位）。 1. 土地成本：100x 2. 太阳能电池板成本：250x 3. 维护成本：100,000 + 100x 总成本：100x + 250x + 100,000 + 100x = 450x + 100,000
助手
设 x 为安装面积（平方英尺）。1. 土地成本：100x 2. 太阳能电池板成本：250x 3. 维护成本：100,000 + 10x 总成本：100x + 250x + 100,000 + 10x = 360x + 100,000 学生的解决方案不正确。他们在维护成本计算中犯了一个错误，使用了 100x 而不是 10x。第一年运营的正确总成本是 360x + 100,000。
策略：使用内心独白或一系列查询来隐藏模型的推理过程
之前的策略表明，在回答特定问题之前，模型对问题进行详细推理有时很重要。对于某些应用，模型得出最终答案所使用的推理过程不适合与用户共享。例如，在辅导应用中，我们可能希望鼓励学生自己找出答案，但模型对学生解决方案的推理过程可能会向学生透露答案。

内心独白是一种可以用来缓解这种情况的策略。内心独白的理念是指示模型将输出中本应对用户隐藏的部分放入结构化格式中，以便于解析它们。然后在将输出呈现给用户之前，对输出进行解析，并且只显示部分输出。

系统
按照以下步骤回答用户的问题。步骤 1 - 首先想出自己的问题解决方案。不要依赖学生的解决方案，因为学生的解决方案可能不正确。将此步骤的所有工作都括在三重引号 (""") 中。步骤 2 - 将您的解决方案与学生的解决方案进行比较，并评估学生的解决方案是否正确。将此步骤的所有工作都括在三重引号 (""") 中。步骤 3 - 如果学生犯了错误，确定您可以在不泄露答案的情况下给学生什么提示。将此步骤的所有工作都括在三重引号 (""") 中。步骤 4 - 如果学生犯了错误，向学生提供上一步的提示（在三重引号之外）。不要写“步骤 4 - ...”，而要写“提示：”。
用户
问题陈述：<插入问题陈述> 学生解决方案：<插入学生解决方案>
或者，这可以通过一系列查询来实现，其中除最后一个查询之外的所有查询的输出都对最终用户隐藏。

首先，我们可以让模型自己解决问题。由于这个初始查询不需要学生的解决方案，因此可以省略。这提供了额外的优势，即模型的解决方案不会受到学生尝试的解决方案的影响。

用户
<插入问题陈述>
接下来，我们可以让模型使用所有可用的信息来评估学生解决方案的正确性。

系统
将您的解决方案与学生的解决方案进行比较，并评估学生的解决方案是否正确。
用户
问题陈述：“”“<插入问题陈述>”“” 您的解决方案：“”“<插入模型生成的解决方案>”“” 学生的解决方案：“”“<插入学生的解决方案>”“”
最后，我们可以让模型利用自己的分析，以乐于助人的导师的身份构建答复。

系统
你是一名数学老师。如果学生犯了错误，请以不透露答案的方式向学生提供提示。如果学生没有犯错，只需给他们一个鼓励的评论。
用户
问题陈述：“”“<插入问题陈述>”“” 您的解决方案：“”“<插入模型生成的解决方案>”“” 学生的解决方案：“”“<插入学生的解决方案>”“” 分析：“”“<插入上一步的模型生成的分析>”“”
策略：询问模型在之前的传递中是否遗漏了什么
假设我们使用模型列出与特定问题相关的来源摘录。列出每个摘录后，模型需要确定是否应该开始编写另一个摘录或是否应该停止。如果源文档很大，模型通常会过早停止并无法列出所有相关摘录。在这种情况下，通常可以通过使用后续查询提示模型来查找之前传递时遗漏的任何摘录来获得更好的性能。

系统
您将获得一份由三重引号分隔的文档。您的任务是选择与以下问题相关的摘录：“人工智能历史上发生了哪些重大的范式转变。”确保摘录包含解释它们所需的所有相关背景 - 换句话说，不要提取缺少重要背景的小片段。以 JSON 格式提供输出，如下所示：[{"excerpt": "..."}, ... {"excerpt": "..."}]
用户
"""<在此处插入文档>"""
助手
[{"excerpt": "模型在此处写一段摘录"}, ... {"excerpt": "模型在此处写另一段摘录"}]
用户
是否有更多相关摘录？注意不要重复摘录。还要确保摘录包含解释它们所需的所有相关背景 - 换句话说，不要提取缺少重要背景的小片段。
策略：使用外部工具
策略：使用基于嵌入的搜索实现高效的知识检索
如果外部信息源作为输入的一部分，模型可以利用这些信息源。这可以帮助模型生成更明智和最新的响应。例如，如果用户询问有关特定电影的问题，将有关该电影的高质量信息（例如演员、导演等）添加到模型的输入中可能会很有用。嵌入可用于实现高效的知识检索，以便可以在运行时将相关信息动态添加到模型输入中。

文本嵌入是一种可以衡量文本字符串之间相关性的向量。相似或相关的字符串会比不相关的字符串更接近。这一事实，加上快速向量搜索算法的存在，意味着嵌入可用于实现高效的知识检索。具体来说，可以将文本语料库分成块，并且可以嵌入和存储每个块。然后可以嵌入给定的查询，并执行向量搜索以从语料库中找到与查询最相关（即在嵌入空间中最接近）的嵌入文本块。

示例实现可以在OpenAI Cookbook中找到。请参阅策略“指示模型使用检索到的知识来回答查询”，了解如何使用知识检索来最大限度地降低模型编造错误事实的可能性的示例。

策略：使用代码执行进行更精确的计算或调用外部 API
语言模型不能依靠自身准确地执行算术或长时间计算。在需要的情况下，可以指示模型编写和运行代码，而不是自己进行计算。具体来说，可以指示模型将要运行的代码放入指定的格式（例如三重反引号）。生成输出后，可以提取并运行代码。最后，如果需要，可以将代码执行引擎（即 Python 解释器）的输出作为模型的输入，以供下一个查询使用。

系统
您可以通过将 Python 代码括在三个反引号中来编写和执行代码，例如“code goes here”。使用它来执行计算。
用户
找出以下多项式的所有实值根：3*x**5 - 5*x**4 - 3*x**3 - 7*x - 10。
代码执行的另一个好用例是调用外部 API。如果模型被指导如何正确使用 API，它就可以编写利用该 API 的代码。可以通过向模型提供文档和/或代码示例来展示如何使用 API，从而指导模型如何使用 API。

系统
您可以通过将 Python 代码括在三个反引号中来编写和执行它。另请注意，您可以访问以下模块来帮助用户向其朋友发送消息：```python import message message.write(to="John", message="嘿，想下班后见面吗？")```
警告：执行模型生成的代码并非天生安全，任何试图执行此操作的应用程序都应采取预防措施。特别是，需要沙盒代码执行环境来限制不受信任的代码可能造成的危害。

策略：让模型访问特定功能
Chat Completions API 允许在请求中传递函数描述列表。这使模型能够根据提供的模式生成函数参数。生成的函数参数由 API 以 JSON 格式返回，可用于执行函数调用。函数调用提供的输出随后可以在以下请求中反馈到模型中以关闭循环。这是使用 OpenAI 模型调用外部函数的推荐方式。要了解更多信息，请参阅我们的入门文本生成指南中的函数调用部分以及OpenAI Cookbook 中的更多函数调用示例。

策略：系统地测试变化
有时很难判断某个变化（例如，新的指令或新的设计）是让你的系统变得更好还是更糟。查看几个示例可能会提示哪个更好，但由于样本量较小，很难区分真正的改进还是随机运气。也许这种变化有助于提高某些输入的性能，但会损害其他输入的性能。

评估程序（或“评估”）对于优化系统设计非常有用。好的评估包括：

代表现实世界的使用情况（或至少是多样化的）
包含许多测试用例以获得更大的统计能力（请参阅下表了解指南）
易于自动化或重复
检测差异	95% 置信度所需的样本量
30％	~10
10％	~100
3%	~1,000
1％	~10,000
输出评估可以由计算机、人类或两者混合完成。计算机可以使用客观标准（例如，只有一个正确答案的问题）以及一些主观或模糊标准自动进行评估，其中模型输出由其他模型查询进行评估。OpenAI Evals是一个开源软件框架，提供用于创建自动评估的工具。

当存在一系列可能的输出，且这些输出的质量同样高时（例如，对于答案较长的问题），基于模型的评估会很有用。基于模型的评估可以实际评估的内容与需要人工评估的内容之间的界限很模糊，并且随着模型功能越来越强大而不断变化。我们鼓励进行实验，以确定基于模型的评估对您的用例的效果如何。

策略：参考黄金标准答案评估模型输出
假设已知一个问题的正确答案应该参考一组特定的已知事实。那么我们可以使用模型查询来计算答案中包含了多少所需的事实。

例如，使用以下系统消息：

系统
您将获得由三重引号分隔的文本，该文本应为问题的答案。检查答案中是否直接包含以下信息： - 尼尔·阿姆斯特朗是第一个踏上月球的人。 - 尼尔·阿姆斯特朗首次踏上月球的日期是 1969 年 7 月 21 日。对于这些要点中的每一个，请执行以下步骤：1 - 重申要点。2 - 提供最接近此要点的答案的引文。3 - 考虑一下，如果不知道主题的人阅读引文，是否可以直接推断出要点。在下定决心之前，解释为什么或为什么不。4 - 如果 3 的答案是肯定的，请写“是”，否则写“否”。最后，提供“是”答案的数量。将此计数提供为 {"count": <在此处插入计数>}。
以下是满足两点的示例输入：

系统
<在上方插入系统消息>
用户
“尼尔·阿姆斯特朗因成为第一个踏上月球的人类而闻名。这一历史性事件发生在 1969 年 7 月 21 日，当时正值阿波罗 11 号任务期间。””
以下是仅满足一个点的示例输入：

系统
<在上方插入系统消息>
用户
“尼尔·阿姆斯特朗创造了历史，他走出登月舱，成为第一个踏上月球的人。””
这是一个不满足任何条件的输入示例：

系统
<在上方插入系统消息>
用户
“1969 年夏天，阿波罗 11 号进行了一次伟大的航行，如传奇之手般大胆。阿姆斯特朗迈出了一步，历史就此展开。他说：“迈出一小步，迈向一个新世界。””
这种基于模型的评估有很多可能的变体。考虑以下变体，它跟踪候选答案和黄金标准答案之间的重叠类型，并跟踪候选答案是否与黄金标准答案的任何部分相矛盾。

系统
使用以下步骤响应用户输入。在继续之前，请完整重述每个步骤。即“步骤 1：推理……”。步骤 1：逐步推理提交的答案与专家答案相比的信息是否是：不相交、相等、子集、超集或重叠（即有交集但不是子集/超集）。步骤 2：逐步推理提交的答案是否与专家答案的任何方面相矛盾。步骤 3：输出 JSON 对象，其结构如下：{"type_of_overlap": "disjoint" or "equal" or "subset" or "superset" or "overlapping", "contradiction": true or false}
下面是一个示例输入，其答案不合标准，但并不与专家答案相矛盾：

系统
<在上方插入系统消息>
用户
问题：“尼尔·阿姆斯特朗因哪件事而最为著名？该事件发生于哪一天？假设为 UTC 时间。”提交的答案：“他不是在月球上行走吗？”专家答案：“尼尔·阿姆斯特朗因成为第一个在月球上行走的人而最为著名。这一历史性事件发生在 1969 年 7 月 21 日。”
以下是一个示例输入，其答案与专家答案直接矛盾：

系统
<在上方插入系统消息>
用户
问题：“尼尔·阿姆斯特朗因哪件事而最为著名？该事件发生于哪一天？假设为 UTC 时间。”” 提交的答案：“1969 年 7 月 21 日，尼尔·阿姆斯特朗成为继巴兹·奥尔德林之后第二个踏上月球的人。”” 专家答案：“尼尔·阿姆斯特朗因成为第一个踏上月球的人而最为著名。这一历史性事件发生于 1969 年 7 月 21 日。””
下面是一个带有正确答案的示例输入，它还提供了比必要更多的细节：

系统
<在上方插入系统消息>
用户
问题：“尼尔·阿姆斯特朗因哪件事而最为著名？该事件发生于哪一天？假设为 UTC 时间。”提交的答案：“1969 年 7 月 21 日 UTC 时间大约 02:56，尼尔·阿姆斯特朗成为第一个踏上月球表面的人，标志着人类历史上的一项重大成就。”专家答案：“尼尔·阿姆斯特朗因成为第一个踏上月球的人而最为著名。这一历史性事件发生于 1969 年 7 月 21 日。”
其他资源
要获得更多灵感，请访问OpenAI Cookbook，其中包含示例代码以及第三方资源的链接，例如：

提示库和工具
提示指南
视频课程
关于通过高级提示提高推理能力的论文
